{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4d7a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/10, Total Reward: 2520, Total Score: 2520\n",
      "Episode: 2/10, Total Reward: 1188, Total Score: 1188\n",
      "Episode: 3/10, Total Reward: 584, Total Score: 584\n",
      "Episode: 4/10, Total Reward: 632, Total Score: 632\n",
      "Episode: 5/10, Total Reward: 772, Total Score: 772\n",
      "Episode: 6/10, Total Reward: 1108, Total Score: 1108\n",
      "Episode: 7/10, Total Reward: 1296, Total Score: 1296\n",
      "Episode: 8/10, Total Reward: 1312, Total Score: 1312\n",
      "Episode: 9/10, Total Reward: 1508, Total Score: 1508\n",
      "Episode: 10/10, Total Reward: 580, Total Score: 580\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque\n",
    "import tkinter as tk\n",
    "import time\n",
    "\n",
    "# Fonction pour initialiser la grille avec deux tuiles au départ\n",
    "def initialize_game():\n",
    "    board = [[0] * 4 for _ in range(4)]\n",
    "    add_new_tile(board)\n",
    "    add_new_tile(board)\n",
    "    return board\n",
    "\n",
    "# Fonction pour ajouter une nouvelle tuile (2 ou 4) à une position vide\n",
    "def add_new_tile(board):\n",
    "    empty_tiles = [(r, c) for r in range(4) for c in range(4) if board[r][c] == 0]\n",
    "    if empty_tiles:\n",
    "        r, c = random.choice(empty_tiles)\n",
    "        board[r][c] = 2 if random.random() < 0.9 else 4\n",
    "\n",
    "# Fonction pour fusionner une ligne ou une colonne de tuiles\n",
    "def merge(line):\n",
    "    non_zero = [num for num in line if num != 0]  # Supprimer les zéros\n",
    "    merged = []\n",
    "    score = 0  # Initialiser le score pour cette ligne\n",
    "    skip = False\n",
    "\n",
    "    for i in range(len(non_zero)):\n",
    "        if skip:\n",
    "            skip = False\n",
    "            continue\n",
    "        if i + 1 < len(non_zero) and non_zero[i] == non_zero[i + 1]:\n",
    "            merged.append(non_zero[i] * 2)\n",
    "            score += non_zero[i] * 2  # Ajouter la valeur fusionnée au score\n",
    "            skip = True\n",
    "        else:\n",
    "            merged.append(non_zero[i])\n",
    "\n",
    "    merged.extend([0] * (len(line) - len(merged)))  # Compléter avec des zéros à droite\n",
    "    return merged, score  # Retourner la ligne fusionnée et le score\n",
    "\n",
    "# Fonction pour déplacer et fusionner les tuiles à gauche\n",
    "def move_left(board):\n",
    "    score = 0  # Initialiser le score pour ce mouvement\n",
    "    for i in range(4):\n",
    "        new_row, gained_score = merge(board[i])  # Fusionner les tuiles et obtenir le score\n",
    "        board[i] = new_row  # Mettre à jour la ligne\n",
    "        score += gained_score  # Ajouter le score obtenu lors de la fusion\n",
    "    return board, score  # Retourner le plateau mis à jour et le score total\n",
    "\n",
    "# Fonction pour déplacer et fusionner les tuiles à droite\n",
    "def move_right(board):\n",
    "    score = 0\n",
    "    for i in range(4):\n",
    "        new_row, gained_score = merge(board[i][::-1])  # Fusionner après avoir inversé la ligne\n",
    "        board[i] = new_row[::-1]  # Réinverser après la fusion\n",
    "        score += gained_score\n",
    "    return board, score\n",
    "\n",
    "# Fonction pour déplacer et fusionner les tuiles vers le haut\n",
    "def move_up(board):\n",
    "    score = 0\n",
    "    for col in range(4):\n",
    "        column = [board[row][col] for row in range(4)]\n",
    "        new_column, gained_score = merge(column)\n",
    "        score += gained_score\n",
    "        for row in range(4):\n",
    "            board[row][col] = new_column[row]\n",
    "    return board, score\n",
    "\n",
    "# Fonction pour déplacer et fusionner les tuiles vers le bas\n",
    "def move_down(board):\n",
    "    score = 0\n",
    "    for col in range(4):\n",
    "        column = [board[row][col] for row in range(4)]\n",
    "        new_column, gained_score = merge(column[::-1])  # Fusionner après avoir inversé la colonne\n",
    "        score += gained_score\n",
    "        for row in range(4):\n",
    "            board[row][col] = new_column[::-1][row]  # Réinverser après la fusion\n",
    "    return board, score\n",
    "\n",
    "# Classe de l'environnement du jeu 2048\n",
    "class Game2048Env:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = initialize_game()\n",
    "        self.total_score = 0  # Ajoute une variable pour suivre le score total du jeu\n",
    "        return np.array(self.board)\n",
    "\n",
    "    def step(self, action):\n",
    "        prev_board = np.copy(self.board)\n",
    "        score = 0  # Initialiser le score\n",
    "\n",
    "        if action == 0:\n",
    "            self.board, score = move_up(self.board)\n",
    "        elif action == 1:\n",
    "            self.board, score = move_down(self.board)\n",
    "        elif action == 2:\n",
    "            self.board, score = move_left(self.board)\n",
    "        elif action == 3:\n",
    "            self.board, score = move_right(self.board)\n",
    "\n",
    "        if not np.array_equal(prev_board, self.board):\n",
    "            add_new_tile(self.board)\n",
    "\n",
    "        # Ajoute le score des fusions réalisées dans ce mouvement au score total\n",
    "        self.total_score += score\n",
    "\n",
    "        done = check_win(self.board) or check_game_over(self.board)\n",
    "\n",
    "        return np.array(self.board), score, done  # Retourner le plateau et le score total pour ce mouvement\n",
    "\n",
    "# Fonction pour vérifier si le joueur a gagné\n",
    "def check_win(board):\n",
    "    return any(2048 in row for row in board)\n",
    "\n",
    "# Fonction pour vérifier s'il reste des déplacements possibles\n",
    "def check_game_over(board):\n",
    "    if any(0 in row for row in board):\n",
    "        return False\n",
    "    for row in board:\n",
    "        for i in range(3):\n",
    "            if row[i] == row[i + 1]:\n",
    "                return False\n",
    "    for col in range(4):\n",
    "        for i in range(3):\n",
    "            if board[i][col] == board[i + 1][col]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Classe DQNAgent pour l'entraînement par renforcement\n",
    "class DQNAgent:\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        self.num_actions = num_actions\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Discount rate\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001  # Learning rate\n",
    "\n",
    "        # Création du modèle de Q-Network et du Target Network\n",
    "        self.model = self.create_model(input_shape, num_actions)\n",
    "        self.target_model = self.create_model(input_shape, num_actions)\n",
    "\n",
    "    def create_model(self, input_shape, num_actions):\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Input(shape=input_shape),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(num_actions, activation='linear')  # Output: Q-values for each action\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        # Met à jour le modèle cible avec les poids du modèle principal\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        # Sauvegarde la transition dans la mémoire\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        # Politique ε-greedy : explore avec probabilité epsilon, sinon exploite\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.num_actions)\n",
    "        q_values = self.model.predict(state, verbose=0)  # Prédit les Q-values pour chaque action\n",
    "        return np.argmax(q_values[0])  # Choisit l'action avec la Q-value la plus élevée\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < 64:  # Attends que la mémoire ait assez d'expériences\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, 64)  # Sélectionne un échantillon de la mémoire\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state, verbose=0)\n",
    "            if done:\n",
    "                target[0][action] = reward  # Récompense si l'épisode est terminé\n",
    "            else:\n",
    "                t = self.target_model.predict(next_state, verbose=0)\n",
    "                target[0][action] = reward + self.gamma * np.amax(t[0])  # Q-value cible\n",
    "\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "        # Réduit epsilon (exploration) au fil du temps\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Interface graphique tkinter pour visualiser l'entraînement\n",
    "class Game2048EnvGUI(Game2048Env):\n",
    "    def __init__(self, root):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.root.title(\"2048 Training\")\n",
    "        self.canvas = tk.Canvas(root, width=400, height=400)\n",
    "        self.canvas.pack()\n",
    "        self.tiles = [[self.canvas.create_text(100 * j + 50, 100 * i + 50, text='', font=(\"Helvetica\", 30))\n",
    "                       for j in range(4)] for i in range(4)]\n",
    "\n",
    "    def update_gui(self):\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                value = self.board[i][j]\n",
    "                self.canvas.itemconfig(self.tiles[i][j], text=str(value) if value != 0 else '')\n",
    "        self.root.update()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    env_gui = Game2048EnvGUI(root)\n",
    "    agent = DQNAgent(input_shape=(4, 4), num_actions=4)\n",
    "    \n",
    "    episodes = 10  # Réduit pour visualiser rapidement\n",
    "    for e in range(episodes):\n",
    "        state = env_gui.reset().reshape(1, 4, 4)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        total_score = 0  # Pour suivre le score total du jeu\n",
    "\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done = env_gui.step(action)\n",
    "            next_state = next_state.reshape(1, 4, 4)\n",
    "\n",
    "            total_reward += reward\n",
    "            total_score = env_gui.total_score  # Suivre le score total\n",
    "            \n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "            env_gui.update_gui()  # Met à jour l'interface graphique avec le nouvel état du jeu\n",
    "            time.sleep(0.5)  # Délai pour visualiser les actions\n",
    "\n",
    "            if done:\n",
    "                print(f\"Episode: {e+1}/{episodes}, Total Reward: {total_reward}, Total Score: {total_score}\")\n",
    "                agent.update_target_model()\n",
    "                \n",
    "        agent.replay()\n",
    "\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
